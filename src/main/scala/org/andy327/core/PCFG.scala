package org.andy327.core

/** Represents a probabilistic context-free grammar rule, assigning a probability to a left-hand side symbol
  * being followed by a series of one or more right-hand side symbols.
  */
class Rule(val lhs: String,
           val rhs: Seq[String],
           val prob: Double = 0.0) {
  override def toString = lhs + " -> " + rhs.mkString(" ")
  def ==(that: Rule): Boolean = toString == that.toString
}

object Rule {
  val pcfgRegex = """(\S+) -> (.*)\t\t([\d\.E-]+)""".r
  val componentsRegex = """(\S+) -> (.*)""".r
  def fromPCFGString(pcfgString: String) = pcfgString match {
    case pcfgRegex(lhs, rhs, prob) => new Rule(lhs, rhs.split(" ").toSeq, prob.toDouble)
    case _ => throw new RuntimeException("Could not parse rule from: " + pcfgString)
  }
}

/** Represents a (binarized) probabilistic context-free grammer (PCFG), which can be trained using
  * a corpus of sentences in the form of part-of-speech tagged tree representations as generated by
  * the output of the LexicalizedParser (see http://nlp.stanford.edu/software/lex-parser.shtml) from
  * the Stanford NLP Parser.
  */
class PCFG(parsedLines: Seq[String]) {
  val ruleCountMap = collection.mutable.Map.empty[String, Int].withDefaultValue(0)
  val lhsCountMap = collection.mutable.Map.empty[String, Int].withDefaultValue(0)
  val ruleProbsMap = collection.mutable.Map.empty[(String, String), Double].withDefaultValue(0.0)

  parsedLines.map(ParseTree.fromTreeString(_)).foreach(addRule(_))
  binarizeGrammar
  calculateRuleProbabilities

  private[core] def addRule(pTree: ParseTree): Unit = {
    if (!pTree.terminal) {
      val rule = new Rule(pTree.label, pTree.children.map(_.label))
      val ruleKey = rule.toString
      val lhsKey = rule.lhs
      ruleCountMap(ruleKey) += 1
      lhsCountMap(lhsKey) += 1

      pTree.children.foreach(addRule(_))
    }
  }

  /** Convert "S -> A B C" to "S -> X1 C" and "X1 -> A B" */
  private[core] def binarizeGrammar = {
    var ruleSplitCount = 0
    val newLabels = collection.mutable.Map.empty[String, String]

    ruleCountMap.keySet.foreach{ ruleKey =>
      val (lhs, rhs) = ruleKey match {
        case Rule.componentsRegex(lhs, rhs) => (lhs, rhs)
        case _ => throw new RuntimeException("Could not parse components from: " + ruleKey)
      }
      val rule = new Rule(lhs, rhs.split(" ").toSeq, 0.0)
      var rhsElems = rule.rhs

      while(rhsElems.size > 2) {
        val newRhs = rhsElems.take(2).mkString(" ")

        ruleSplitCount += { if (newLabels.contains(newRhs)) 0 else 1 }
        val newLhs = newLabels.getOrElse(newRhs, "X" + ruleSplitCount)

        lhsCountMap(newLhs) += 1
        ruleCountMap(newLhs + " -> " + newRhs) += 1

        rhsElems = (newLhs +: rhsElems.tail.tail)
        val key = lhs + " -> " + rhsElems.mkString(" ")
        ruleCountMap(key) = ruleCountMap(rule.toString)
        ruleCountMap.remove(rule.toString)
      }
    }
  }

  private[core] def calculateRuleProbabilities = {
    ruleCountMap.keySet.foreach{
      rule => rule match {
        case Rule.componentsRegex(lhs, rhs) => ruleProbsMap((lhs, rhs)) = ruleCountMap(rule).toDouble / lhsCountMap(lhs)
        case _ => throw new RuntimeException("Could not parse rule from: " + rule)
      }
    }
  }
}

object PCFG {
  def fromFile(filepath: String) = {
    val rawLines = scala.io.Source.fromFile(filepath).getLines.toSeq
    val lines = rawLines.flatMap(_.replaceAll("\\(ROOT", "#\\(ROOT").replaceAll("\\s+", " ").split("#").tail)
    new PCFG(lines)
  }
}
